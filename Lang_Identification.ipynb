{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lang_Identification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCok7Sl6Eyna"
      },
      "source": [
        "# 1. Driver Code - Starting Point\n",
        "# 2. Language Identification Algorithm Class\n",
        "#     1. Public methods for driving identification process\n",
        "#       0. Min Distance returning function\n",
        "#       1. Profile Calculation\n",
        "#       2. Tri-gram Calculation\n",
        "#       3. Distance Calculation for all Languages\n",
        "#         1. Distance Calculation for specific language\n",
        "#     2. Constructor (if required)\n",
        "#     3. Private Members\n",
        "#       1. Corpus\n",
        "#         1. An Crubadan\n",
        "#       2. N-gram specific Parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A17WmCsGg4AB",
        "outputId": "4977c863-9bd2-4899-d9d4-75c4820d8619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "!pip install regex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (2019.12.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36dp6EcIAymB"
      },
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMfDmohrCVG_"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "from nltk.corpus import crubadan\n",
        "from nltk.util import trigrams\n",
        "from nltk import word_tokenize\n",
        "from nltk import FreqDist\n",
        "    # Frequency Distribution\n",
        "\n",
        "class LanguagePredictionAlgo:\n",
        "\n",
        "  # Constructor\n",
        "  # self => this in C++/Java\n",
        "  def __init__(self):\n",
        "    '''\n",
        "    Initialization of libraries\n",
        "    Initialization of Corpus\n",
        "    '''\n",
        "\n",
        "    self.corpus = crubadan\n",
        "\n",
        "    for language in self.corpus.langs():\n",
        "      self.corpus.lang_freq(language)\n",
        "\n",
        "  # def clear_punctuations(self, text):\n",
        "  #   '''\n",
        "  #   Clear the punctuation marks to clean the text\n",
        "  #   '''\n",
        "  #   all_punctuations = \"\"\"!#$%|()*+\"\"\"\n",
        "  #   clean_string = re.sub([{all_punctuations}], '', text)\n",
        "  #   return clean_string\n",
        "\n",
        "  def clear_punctuations(self, text):\n",
        "    '''\n",
        "    Clear the punctuation marks to clean the text\n",
        "    '''\n",
        "\n",
        "    return regex.sub(r\"[^\\P{P}\\']+\", \"\", text) \n",
        "  \n",
        "  def ngram_profile(self, text):\n",
        "    '''\n",
        "    Generate the trigram profile of the text\n",
        "    '''\n",
        "    clean_text = self.clear_punctuations(text)\n",
        "    tokens = word_tokenize(clean_text)\n",
        "\n",
        "    profile = FreqDist()\n",
        "\n",
        "    for token in tokens:\n",
        "      token_trigrams_gen = trigrams(\"<\" + token + \">\")\n",
        "      joined_trigrams = [\"\".join(t) for t in token_trigrams_gen]\n",
        "\n",
        "      for one_trigram in joined_trigrams:\n",
        "        if one_trigram in profile:\n",
        "          profile[one_trigram] += 1\n",
        "        else:\n",
        "          profile[one_trigram] = 1\n",
        "\n",
        "      return profile\n",
        "\n",
        "  def calc_dist(self, lang, trigram, text_profile):\n",
        "    # Calculate the out-of-place measure between a trigram's position in\n",
        "    # the crubadan lang profile and text_profile\n",
        "    # \"Index of a trigram in the profile\"\n",
        "    # lang -> each language in the An Crubadan corpus\n",
        "    # trigram -> individiual trigram characterwise <further> -> <fu, fur, urt.....\n",
        "    # text_profile -> trigram profile of the Hindi text\n",
        "\n",
        "    lang_profile = self.corpus.lang_freq(lang)\n",
        "    dist = 0\n",
        "\n",
        "    if trigram in lang_profile:\n",
        "      lang_profile_index = list(lang_profile.keys()).index(trigram)\n",
        "      # [how frequent is trigram in lang_profile]\n",
        "      text_index = list(text_profile.keys()).index(trigram)\n",
        "\n",
        "      dist = abs(lang_profile_index - text_index)\n",
        "    else:\n",
        "      dist = 999999999\n",
        "      # import sys; sys.maxsize\n",
        "  \n",
        "    return dist\n",
        "\n",
        "\n",
        "  def get_all_lang_dists(self, text):\n",
        "    distances = {}\n",
        "    text_profile = self.ngram_profile(text)\n",
        "\n",
        "    for lang in self.corpus._all_lang_freq.keys():\n",
        "      lang_dist = 0\n",
        "      for trigram in text_profile:\n",
        "        lang_dist += self.calc_dist(lang, trigram, text_profile)\n",
        "\n",
        "      distances[lang] = lang_dist\n",
        "    \n",
        "    return distances\n",
        "  \n",
        "  def predict_lang(self, text):\n",
        "    all_lang_distances = self.get_all_lang_dists(text)\n",
        "    return min(all_lang_distances, key=all_lang_distances.get)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EEzY7Zngh3K",
        "outputId": "7413c2c3-8643-4c96-c591-136cc00f68df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Driver Code\n",
        "def identify_lang():\n",
        "  lp = LanguagePredictionAlgo()\n",
        "\n",
        "  # text = \"I am a teacher\"\n",
        "  # text = \"तब से कई अन्य परियोजनाओं को सम्पादकीय कारणों से विकिपीडिया से अलग किया गया है।\"\n",
        "  text = \"The school's traditions include a 600-year-old ceremony in which the warden, wearing the Founder's Ring, admits each new scholar; \\\"Illumina\\\", an autumn celebration, in which candles are placed into niches all over the medieval walls around the playing fields; and \\\"Morning Hills\\\", held once a year, when all the school's pupils and teachers climb St Catherine's Hill for a roll call and prayers.\"\n",
        "\n",
        "  # fr, ger, eng, hin - trigram profiles\n",
        "  # text_profile vs fr; text_profile vs ger, text_profile vs eng; text_profile vs hin\n",
        "  print(lp.predict_lang(text))\n",
        "\n",
        "identify_lang()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eng\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRyQ8EtnKqEX",
        "outputId": "d7bf7b9f-6567-4f70-a8e3-911855a71d2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "\n",
        "# from nltk.util import trigrams\n",
        "# tokens = word_tokenize('I am noob')\n",
        "# for token in tokens:\n",
        "#   token_trigrams = trigrams(token)\n",
        "#   print(token_trigrams)\n",
        "#   trigram = [\"\".join(t) for t in token_trigrams]\n",
        "#   print(trigram)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<generator object trigrams at 0x7f40e7086fc0>\n",
            "[]\n",
            "<generator object trigrams at 0x7f40e72e4200>\n",
            "[]\n",
            "<generator object trigrams at 0x7f40e70869e8>\n",
            "['noo', 'oob']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OELM9lHQLqq4"
      },
      "source": [
        "from nltk import FreqDist\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uftpfgfOSuq"
      },
      "source": [
        "a = FreqDist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCa4d42COUay",
        "outputId": "b7146dd3-a738-408f-8230-40c8a6d65d16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xCzAPLEOVXM"
      },
      "source": [
        "from nltk.corpus import crubadan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4EE4HcLcu7S"
      },
      "source": [
        "for language in crubadan.langs():\n",
        "  crubadan.lang_freq(language)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vlRbxNedE7M",
        "outputId": "6a289ba5-a570-40bc-ed26-2f5d6d8474eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "crubadan._all_lang_freq.keys() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['abk', 'abn', 'ace', 'ach', 'acu', 'ada', 'afr', 'agr', 'aja', 'aka', 'ako', 'alt', 'amc', 'ame', 'amh', 'ami', 'amr', 'arg', 'ang', 'arb', 'arl', 'arn', 'asm', 'ast', 'ava', 'ayr', 'azj', 'bak', 'bcc', 'ban', 'bar', 'bas', 'bba', 'bci', 'bel', 'bem', 'bfa', 'bul', 'bho', 'bis', 'bcl', 'bin', 'bam', 'ben', 'boa', 'bod', 'bre', 'bos', 'btb', 'bxr', 'buc', 'bug', 'bum', 'byv', 'cab', 'cat', 'cak', 'cbr', 'cbs', 'cbt', 'cbu', 'ceb', 'cha', 'chj', 'chk', 'chw', 'cic', 'cjk', 'cnh', 'cni', 'cos', 'cop', 'cot', 'cpu', 'crk', 'crs', 'csa', 'csb', 'ces', 'chu', 'cuk', 'chv', 'cym', 'czt', 'dan', 'dag', 'dar', 'ddn', 'deu', 'dga', 'dhv', 'diq', 'dsb', 'dua', 'dyo', 'dyu', 'dzo', 'ewe', 'efi', 'ell', 'emk', 'eml', 'eng', 'eng ', 'epo', 'spa', 'est', 'eus', 'pes', 'fub', 'fin', 'fij', 'fao', 'fon', 'fra', 'frr', 'frp', 'fud', 'fuf', 'fur', 'fri', 'gaa', 'gle', 'gag', 'gya', 'gla', 'gil', 'gjn', 'gkn', 'glg', 'gug', 'got', 'gsc', 'gsw', 'guc', 'guj', 'guw', 'glv', 'gym', 'hau', 'haw', 'heb', 'hin', 'hil', 'hna', 'hne', 'hni', 'hmo', 'hrv', 'hsb', 'hat', 'hun', 'huu', 'hve', 'hye', 'her', 'ina', 'iba', 'ind', 'ibo', 'igl', 'ilo', 'inh', 'isl', 'iso', 'ita', 'its', 'ike', 'ivv', 'jiv', 'jav', 'kab', 'kac', 'kat', 'kam', 'kbd', 'kbp', 'kcc', 'kck', 'kde', 'kek', 'kng', 'kha', 'kik', 'kua', 'kjh', 'kaz', 'kal', 'kmb', 'khm', 'kan', 'knn', 'koo', 'kos', 'gkp', 'kqn', 'krc', 'knc', 'kri', 'ksh', 'ktu', 'kmr', 'kum', 'kpv', 'kwf', 'cor', 'kwn', 'kir', 'lad', 'lat', 'lbe', 'ltz', 'lch', 'lug', 'lgg', 'lia', 'nld', 'lij', 'lld', 'lmo', 'lms', 'lnc', 'lin', 'lns', 'lao', 'lol', 'loz', 'lit', 'lua', 'lue', 'lub', 'lun', 'luo', 'lus', 'lav', 'mad', 'mam', 'mau', 'maz', 'mcd', 'mcf', 'mdf', 'men', 'meu', 'mfe', 'plt', 'mah', 'mhi', 'mho', 'mic', 'mri', 'min', 'miq', 'mir', 'mkd', 'mal', 'mlu', 'khk', 'ron', 'mos', 'mar', 'mrj', 'mly', 'mlt', 'mua', 'mus', 'mwv', 'mxv', 'mya', 'myv', 'mzn', 'nau', 'nhe', 'nap', 'naq', 'nba', 'nob', 'ndc', 'nde', 'nds', 'nep', 'nen', 'ndo', 'ngl', 'nia', 'niu', 'nmf', 'nnb', 'nno', 'not', 'nbl', 'nso', 'nav', 'nya', 'nyk', 'nym', 'nyn', 'nzi', 'ogo', 'ojw', 'gaz', 'ood', 'ori', 'oss', 'pan', 'pag', 'pam', 'pap', 'pau', 'pbb', 'pcm', 'pdc', 'pem', 'pih', 'pis', 'pol', 'pms', 'pon', 'ppl', 'prq', 'prs', 'prv', 'pbu', 'por', 'quh', 'qug', 'rar', 'rcf', 'roh', 'rnd', 'run', 'rmn', 'rus', 'rug', 'rup', 'kin', 'sba', 'src', 'scn', 'sco', 'snd', 'sme', 'seh', 'sag', 'shp', 'shs', 'sid', 'slk', 'slv', 'smo', 'sna', 'snk', 'som', 'ses', 'sop', 'als', 'srp', 'srm', 'srn', 'srr', 'ssw', 'sot', 'sun', 'suk', 'sum', 'sus', 'swe', 'swb', 'swh', 'tab', 'tam', 'tbz', 'tel', 'tem', 'teo', 'tet', 'tgk', 'tha', 'tir', 'tig', 'tiv', 'tuk', 'tkl', 'tgl', 'tll', 'tsn', 'tob', 'ton', 'toi', 'toj', 'tos', 'tpi', 'tur', 'tsc', 'tso', 'tat', 'ttj', 'tum', 'tvl', 'tah', 'tzc', 'tzm', 'udm', 'uig', 'ukr', 'umb', 'ura', 'urd', 'urh', 'uzn', 'vec', 'ven', 'vie', 'vls', 'vmf', 'vmw', 'wal', 'war', 'wls', 'wol', 'xal', 'xho', 'xsm', 'yad', 'yaf', 'yao', 'yap', 'ydd', 'yor', 'yua', 'ccx', 'zai', 'zea', 'cmn', 'zne', 'zpa', 'zul'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX29BIimeY5F"
      },
      "source": [
        "# dict.get(lang) => lang_dist\n",
        "\n",
        "# dd = {\n",
        "#     key_1: val_1,\n",
        "#     key_2: val_2,\n",
        "#     key_3: val_3\n",
        "# }\n",
        "# distances = {\n",
        "#     \"ger\": 100,\n",
        "#     \"hin\": 2,\n",
        "#     \"eng\": 200,\n",
        "#     \"fre\": 2000\n",
        "# }\n",
        "\n",
        "\n",
        "# ll = [\n",
        "#  [1, 2],\n",
        "#  [2, 4],\n",
        "#  [6, -1]\n",
        "# ]\n",
        "\n",
        "\n",
        "# Comparator -\n",
        "# a < b\n",
        "# a == b\n",
        "# a > b\n",
        "\n",
        "# a < b\n",
        "# numerical_val(a) - numerical_val(b)\n",
        "# +1 => a > b \n",
        "# -1 => a < b\n",
        "# 0 => a == b\n",
        "\n",
        "# a = [\n",
        "#   a[i] = [1, 2],\n",
        "#   a[i + 1] = [3, 7],\n",
        "#   a[i + 2] = [4, 5],\n",
        "#  .\n",
        "#  .\n",
        "#  .\n",
        "#  .\n",
        "# ]\n",
        "\n",
        "# (a[i] vs a[j])\n",
        "# custom_comparator(i, j) {\n",
        "#    if (a[i][1] > a[j][1]) {\n",
        "#        return +1;\n",
        "#    }\n",
        "#    else if (a[i][1] < a[j][1]) {\n",
        "#      return -1;\n",
        "#    } \n",
        "#    else {\n",
        "#        return 0\n",
        "#    }\n",
        "# }\n",
        "\n",
        "\n",
        "# eng_profile = {\n",
        "#     trigram_1: freq_1,\n",
        "#     trigram_2: freq_2, \n",
        "# }\n",
        "# [trigram_2, trigram_1]\n",
        "\n",
        "# (french test text)\n",
        "# text_profile = {\n",
        "#     tri_1: fre_1,\n",
        "#     tri_2: fre_2\n",
        "# }\n",
        "# [tri_2, tri_1]\n",
        "\n",
        "# if (tri_1 == trigram_2)\n",
        "# abs(index(tri_1) - index(trigram_2))\n",
        "\n",
        "# if (trigram_1 != tri_2)\n",
        "#   sys.maxsize, MAXINT, +999999999 => >>>>>>>>> distance\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}